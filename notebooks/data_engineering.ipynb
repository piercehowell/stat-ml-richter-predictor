{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Description of Data (from DrivenData)\n",
    "There are 39 columns in the dataset. The first column is the `building_id`, and other 38 columns are features about the buildings. All the categorical type variables represented by lowercase characters.\n",
    "\n",
    "\n",
    "\n",
    "- `geo_level_1_id`, `geo_level_2_id`, `geo_level_3_id` **(type: int)**: geographic region in which building exists, from largest (level 1) to most specific sub-region (level 3). Possible values: level 1: 0-30, level 2: 0-1427, level 3: 0-12567.\n",
    "- `count_floors_pre_eq` **(type: int)**: number of floors in the building before the earthquake.\n",
    "- `age` **(type: int)**: age of the building in years.\n",
    "- `area_percentage` **(type: int)**: normalized area of the building footprint.\n",
    "- `height_percentage` **(type: int)**: normalized height of the building footprint.\n",
    "- `land_surface_condition` **(type: categorical)**: surface condition of the land where the building was built. Possible values: n, o, t.\n",
    "- `foundation_type` **(type: categorical)**: type of foundation used while building. Possible values: h, i, r, u, w.\n",
    "- `roof_type` **(type: categorical)**: type of roof used while building. Possible values: n, q, x.\n",
    "- `ground_floor_type` **(type: categorical)**: type of the ground floor. Possible values: f, m, v, x, z.\n",
    "- `other_floor_type` **(type: categorical)**: type of constructions used in higher than the ground floors (except of roof). Possible values: j, q, s, x.\n",
    "- `position` **(type: categorical)**: position of the building. Possible values: j, o, s, t.\n",
    "- `plan_configuration` **(type: categorical)**: building plan configuration. Possible values: a, c, d, f, m, n, o, q, s, u.\n",
    "- `has_superstructure_adobe_mud` **(type:  binary)**: flag variable that indicates if the superstructure was made of Adobe/Mud.\n",
    "- `has_superstructure_mud_mortar_stone` **(type:  binary)**: flag variable that indicates if the superstructure was made of Mud Mortar - Stone.\n",
    "- `has_superstructure_stone_flag` **(type:  binary)**: flag variable that indicates if the superstructure was made of Stone.\n",
    "- `has_superstructure_cement_mortar_stone` **(type:  binary)**: flag variable that indicates if the superstructure was made of Cement Mortar - Stone.\n",
    "- `has_superstructure_mud_mortar_brick` **(type:  binary)**: flag variable that indicates if the superstructure was made of Mud Mortar - Brick.\n",
    "- `has_superstructure_cement_mortar_brick` **(type:  binary)**: flag variable that indicates if the superstructure was made of Cement Mortar - Brick.\n",
    "- `has_superstructure_timber` **(type:  binary)**: flag variable that indicates if the superstructure was made of Timber.\n",
    "- `has_superstructure_bamboo` **(type:  binary)**: flag variable that indicates if the superstructure was made of Bamboo.\n",
    "- `has_superstructure_rc_non_engineered` **(type:  binary)**: flag variable that indicates if the superstructure was made of non-engineered reinforced concrete.\n",
    "- `has_superstructure_rc_engineered` **(type:  binary)**: flag variable that indicates if the superstructure was made of engineered reinforced concrete.\n",
    "- `has_superstructure_other` **(type:  binary)**: flag variable that indicates if the superstructure was made of any other material.\n",
    "- `legal_ownership_status` **(type: categorical)**: legal ownership status of the land where building was built. Possible values: a, r, v, w.\n",
    "- `count_families` **(type: int)**: number of families that live in the building.\n",
    "- `has_secondary_use` **(type:  binary)**: flag variable that indicates if the building was used for any secondary purpose.\n",
    "- `has_secondary_use_agriculture` **(type:  binary)**: flag variable that indicates if the building was used for agricultural purposes.\n",
    "- `has_secondary_use_hotel` **(type:  binary)**: flag variable that indicates if the building was used as a hotel.\n",
    "- `has_secondary_use_rental` **(type:  binary)**: flag variable that indicates if the building was used for rental purposes.\n",
    "- `has_secondary_use_institution` **(type:  binary)**: flag variable that indicates if the building was used as a location of any institution.\n",
    "- `has_secondary_use_school` **(type:  binary)**: flag variable that indicates if the building was used as a school.\n",
    "- `has_secondary_use_industry` **(type:  binary)**: flag variable that indicates if the building was used for industrial purposes.\n",
    "- `has_secondary_use_health_post` **(type:  binary)**: flag variable that indicates if the building was used as a health post.\n",
    "- `has_secondary_use_gov_office` **(type:  binary)**: flag variable that indicates if the building was used fas a government office.\n",
    "- `has_secondary_use_use_police` **(type:  binary)**: flag variable that indicates if the building was used as a police station.\n",
    "- `has_secondary_use_other` **(type:  binary)**: flag variable that indicates if the building was secondarily used for other purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"../data/\"\n",
    "features_df = pd.read_csv(os.path.join(data_dir, \"train_values.csv\"))\n",
    "labels_df = pd.read_csv(os.path.join(data_dir, \"train_labels.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "# I am starting out not using all variables\n",
    "int_columns = ['geo_level_1_id', 'geo_level_2_id', 'geo_level_3_id',\n",
    "               'count_floors_pre_eq', 'age', 'area_percentage', \n",
    "               'height_percentage']\n",
    "data_dir = \"../data/\"\n",
    "features_df = pd.read_csv(os.path.join(data_dir, \"train_values.csv\"))\n",
    "labels_df = pd.read_csv(os.path.join(data_dir, \"train_labels.csv\"))\n",
    "categ_columns = ['land_surface_condition', 'foundation_type', 'roof_type',\n",
    "                 'ground_floor_type', 'other_floor_type', 'position',\n",
    "                 'plan_configuration',\n",
    "                 ]\n",
    "binary_columns = ['has_superstructure_adobe_mud', 'has_superstructure_mud_mortar_stone',\n",
    "                  'has_superstructure_stone_flag', 'has_superstructure_cement_mortar_stone',\n",
    "                  'has_superstructure_mud_mortar_brick', 'has_superstructure_cement_mortar_brick',\n",
    "                  'has_superstructure_timber', 'has_superstructure_bamboo', 'has_superstructure_rc_engineered',\n",
    "                  'has_superstructure_other'\n",
    "                  ]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size information:\n",
      "\t Number of Training Samples: 5003520\n",
      "\t Number of Validation Samples: 1250904\n",
      "(52121, 51)\n",
      "[-0.48883051  1.26838563  1.33425667 -1.55599329 -0.08965615 -0.23745165\n",
      " -1.26606033  0.          0.          1.          0.          0.\n",
      "  1.          0.          0.          1.          0.          0.\n",
      "  1.          0.          0.          0.          0.          1.\n",
      "  0.          0.          0.          0.          0.          1.\n",
      "  0.          0.          0.          1.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  1.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.        ]\n"
     ]
    }
   ],
   "source": [
    "# Create pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# select only the columns we want\n",
    "X = features_df[ int_columns + categ_columns + binary_columns]\n",
    "y = labels_df\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Size information:\")\n",
    "print(\"\\t Number of Training Samples: {}\".format(X_train.size))\n",
    "print(\"\\t Number of Validation Samples: {}\".format(X_val.size))\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categ_transformer = Pipeline(steps=[\n",
    "    ('encoder', OneHotEncoder())\n",
    "])\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('numeric', numeric_transformer, int_columns),\n",
    "        ('categorical', categ_transformer, categ_columns),\n",
    "        ('passthrough', 'passthrough', binary_columns)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# preprocess the data\n",
    "X_train = preprocessor.fit_transform(X_train)\n",
    "X_val = preprocessor.fit_transform(X_val)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
